---
title: "Regularized_models"
author: "Steven Chao, Tanaya Kavathekar, Madhuri Yadav, Amna Gul"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    fig_height: 4.5
    fig_width: 7
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_float: true
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r loadlibraries, include=F}
loadPkg("tidyverse")
loadPkg("glmnet")
loadPkg("dplyr")
loadPkg("caret")
loadPkg("dataPreparation")
loadPkg("factoextra")
loadPkg("dummies")
```

```{r udf}
train_test_split = function(df_sub) {
  # Split the data into training and test set
  set.seed(123)
  training.samples <- df_sub$tip_fare_ratio %>%
    createDataPartition(p = 0.8, list = FALSE)
  
  # Build X_train, y_train, X_test, y_test
  X_train <- df_sub[training.samples, names(df_sub) != "tip_fare_ratio"]
  y_train <- df_sub[training.samples, "tip_fare_ratio"]
  
  X_test <- df_sub[-training.samples, names(df_sub) != "tip_fare_ratio"]
  y_test <- df_sub[-training.samples, "tip_fare_ratio"]
  
  # create list of the return variables
  dfs_list <- list("X_train" = X_train, "y_train" = y_train, "X_test" = X_test, "y_test" = y_test) 
  return(dfs_list)
}

```

# Data

```{r }
df <- read.csv("../Data/taxidata_processed_project2.csv")
colnames(df)

df_sub <- df[,c("tip_fare_ratio", "VendorID",  "passenger_count", "trip_distance", "fare_amount", "congestion_surcharge", "Borough_pu", "Borough_do", "pickup_period", "drop_period", "trip_duration")]

df_sub[,c("VendorID",  "passenger_count")] <- lapply(df_sub[,c("VendorID",  "passenger_count")], factor)

#numerical_col:
condition <- (!names(df_sub) == "tip_fare_ratio") & (!sapply(df_sub, class) == "factor")
```

# EDA

```{r correlation}
cor(df_sub[,condition], df_sub[,c("tip_fare_ratio")], method = c("pearson", "kendall", "spearman"))

```

```{r scatterplots}

```

# Model building

## Test train split
To avoid introducing a bias in test using train-data, the train-test split should be performed before (most) data preparation steps.

To simulate a train and test set we are going to split randomly this data set into 80% train and 20% test.

```{r split the data}
# one hot encoding 
sub_factor_col <- (!names(df_sub) == "tip_fare_ratio") & (sapply(df_sub, class) == "factor")
new_df_sub <- dummy.data.frame(df_sub[,c(sub_factor_col)],  sep="_")

com_df_sub <- cbind(df_sub[,c((!sapply(df_sub, class) == "factor"))], new_df_sub)

#train and test split
splitted_dfs <- train_test_split(com_df_sub)
```

## Scaling variables
We need to scale the test and train using train scale values hence first compute scales 
```{r scale parameter}
scales <- build_scales(dataSet = splitted_dfs["X_train"]$X_train, cols = c(names(df_sub[,condition])), verbose = TRUE)
print(scales)
```

All the variables has different means and std hence we need to scale all the variables present above.

```{r }
X_train <- fastScale(dataSet = splitted_dfs["X_train"]$X_train, scales = scales, verbose = TRUE)
X_test <- fastScale(dataSet = splitted_dfs["X_test"]$X_test, scales = scales, verbose = TRUE)
```

```{r }
train <- cbind(X_train, data.frame("tip_fare_ratio" = splitted_dfs["y_train"]$y_train))
test <- cbind(X_test, data.frame("tip_fare_ratio" = splitted_dfs["y_test"]$y_test))
```

# Principal component analysis

We have to use one hot encoding to convert factor variables into numerical variables
```{r }
sub_factor_col <- (!names(df_sub) == "tip_fare_ratio") & (sapply(df_sub, class) == "factor")
new_df_sub <- dummy.data.frame(df_sub[,c(sub_factor_col)],  sep="_")

com_df_sub <- cbind(df_sub[,c((!sapply(df_sub, class) == "factor"))], new_df_sub)

splitted_dfs <- train_test_split(com_df_sub)

X_train <- splitted_dfs["X_train"]$X_train

pr.out =prcomp(X_train)
summary(pr.out)
pr.out
```
## Variable selection

Stepwise regression
```{r }
loadPkg("olsrr")
model <- lm(tip_fare_ratio ~ ., data = train)
k <- ols_step_all_possible(model)
plot(k)

write.csv(k, "stepwise_models.csv")

write.csv(train, "train.csv")

```

## Linear models:
### Ridge
Ridge model:
```{r }
#train <- na.omit(train)
x=model.matrix(tip_fare_ratio~.,train)[,-1]
y = train %>%
  select(tip_fare_ratio) %>%
  unlist() %>%
  as.numeric()

#grid = 10^seq(10, -2, length = 100)
set.seed(123)
cv_lamda = cv.glmnet(x, y, alpha = 0)
# Display the best lambda value
cv_lamda$lambda.min


# Fit the final model on the training data
ridge_model <- glmnet(x, y, alpha = 0, lambda = cv_lamda$lambda.min)
# Display regression coefficients
coef(ridge_model)

predict.glmnet(ridge_mod, s = 0, exact = T)
dim(coef(ridge_mod))
plot(ridge_mod)

```



```{r }
wmape <- function(actual,pred){
           wmape <- (mean(abs(actual - pred))/sum(abs(actual)))*100
           mape <- mean(abs((actual - pred)/actual))*100
           return (wmape)
}

mape <- function(actual,pred){
           mape <- mean(abs((actual - pred)/actual))*100
           return (mape)
}

```

```{r }
# Make predictions on the test data
x.test <- model.matrix(tip_fare_ratio ~., test)[,-1]
predictions <- ridge_model %>% predict(x.test) %>% as.vector()
# Model performance metrics
data.frame(
  wmape = wmape(predictions, test.data$tip_fare_ratio),
  mape = mape(predictions, test.data$tip_fare_ratio),
  Rsquare = R2(predictions, test.data$tip_fare_ratio)
)

check <- data.frame(predictions, test.data$tip_fare_ratio)
```

### Lasso
```{r }
# Find the best lambda using cross-validation
set.seed(123) 
lasso_cv <- cv.glmnet(x, y, alpha = 1)
# Display the best lambda value
lasso_cv$lambda.min
```

```{r }
# Fit the final model on the training data
lasso_model <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min)
# Dsiplay regression coefficients
coef(lasso_model)
```


```{r }
# Make predictions on the test data
x.test <- model.matrix(tip_fare_ratio ~., test)[,-1]
predictions <- lasso_model %>% predict(x.test) %>% as.vector()
# Model performance metrics
data.frame(
  wmape = wmape(predictions, test.data$tip_fare_ratio),
  mape = mape(predictions, test.data$tip_fare_ratio),
  Rsquare = R2(predictions, test.data$tip_fare_ratio)
)
```


### Elastic net


### Decision Tree

```{r dt_growtreelog}
# Grow decision tree
taxi_tree_log <- tree(tip_fare_ratio ~ ., data = train, mindev=0.001)

# Print results
summary(taxi_tree_log)
#png(file="test.png",width=900,height=900,res=30)
plot(taxi_tree_log) 
text(taxi_tree_log, cex = 0.75) #2.5)
#dev.off()
```


```{r dt_prunetreelogtrain}
# Return best pruned tree with 5 leaves, evaluating error on training data 
taxi_tree_log_prune_train <- prune.tree(taxi_tree_log, best = 5)

# Print results
summary(taxi_tree_log_prune_train)
plot(taxi_tree_log_prune_train) 
text(taxi_tree_log_prune_train, cex = 0.75)


# Create sequence of pruned tree sizes/errors
log_prune_train_seq = prune.tree(taxi_tree_log)

# Plot error versus plot size
plot(log_prune_train_seq) 

log_prune_train_seq$dev # Vector of error
# rates for prunings, in order
optimal_tree_log_train = which(log_prune_train_seq$dev == min(log_prune_train_seq$dev)) 
# Positions of
# optimal (with respect to error) trees 
min(log_prune_train_seq$size[optimal_tree_log_train])
```
```{r}
tree_pred = predict(taxi_tree_log, newdata = test)
tree_mse1 = (sum((tree_pred - test$tip_fare_ratio)^2)) / nrow(test)
tree_mse1
```

